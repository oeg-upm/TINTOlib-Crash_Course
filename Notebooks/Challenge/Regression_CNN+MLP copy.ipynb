{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EybOZ6hSjpCF"
   },
   "source": [
    "<h1><font color=\"#113D68\" size=6>TINTOlib: Converting Tidy Data into Synthetic Images</font></h1>\n",
    "\n",
    "<h1><font color=\"#113D68\" size=5>Template Regression problem with a Hibryd Network (CNN+MLP)</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#113D68\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#113D68\" size=3>Raúl García-Castro</font><br>\n",
    "<font color=\"#113D68\" size=3>Jiayun Liu</font><br>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qfTSDDUqiDB0"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "More information about [Manuel Castillo-Cara](https://www.manuelcastillo.eu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQJGKuJDiDB0"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "More information about [Raúl García-Castro](http://www.garcia-castro.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EdXBV6dtiDB0"
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Licencia</font></h2>\n",
    "\n",
    "<p><small><small>Improving Deep Learning by Exploiting Synthetic Images Copyright 2024 Manuel Castillo Cara.</p>\n",
    "<p><small><small> Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at </p>\n",
    "<p><small><small> <a href=\"https://www.apache.org/licenses/LICENSE-2.0\">https://www.apache.org/licenses/LICENSE-2.0</a> </p>\n",
    "<p><small><small> Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l5nFzsdjpCW"
   },
   "source": [
    "---\n",
    "\n",
    "<a id=\"indice\"></a>\n",
    "<h2><font color=\"#004D7F\" size=5>Index</font></h2>\n",
    "\n",
    "* [0. Context](#section0)\n",
    "* [1. Description](#section1)\n",
    "    * [1.1. Main Features](#section11)\n",
    "    * [1.2. Citation](#section12)\n",
    "    * [1.3. Documentation and License](#section13)\n",
    "* [2. Libraries](#section2)\n",
    "    * [2.1. System setup](#section21)\n",
    "    * [2.2. Invoke the libraries](#section22)\n",
    "* [3. Data processing](#section3)\n",
    "    * [3.1. TINTOlib methods](#section31)\n",
    "    * [3.2. Read the dataset](#section32)\n",
    "    * [3.3. Generate images](#section33)\n",
    "    * [3.4. Read images](#section34)\n",
    "    * [3.5. Mix images and tidy data](#section35)\n",
    "* [4. Pre-modelling phase](#section4)\n",
    "    * [4.1. Data curation](#section41)\n",
    "* [5. Modelling hybrid network](#section5)\n",
    "    * [5.1. FFNN for tabular data](#section51)\n",
    "    * [5.2. CNN for TINTOlib images](#section52)\n",
    "    * [5.3. Concatenate branches](#section53)\n",
    "    * [5.4. Metrics](#section54)\n",
    "    * [5.5. Compile and fit](#section55)\n",
    "* [6. Results](#section6)\n",
    "    * [6.1. Train/Validation representation](#section61)\n",
    "    * [6.2. Validation/Test evaluation](#section62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SxTpMExHjpCa"
   },
   "source": [
    "---\n",
    "<a id=\"section0\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 0. Context</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlVYt3MRrl_V"
   },
   "source": [
    "This tutorial explains how to read images generated by TINTOlib and input them into a Hybrid Neural Network, which combines a Convolutional Neural Network (CNN) and a Multi-Layer Perceptron (MLP). Ensure that the images have already been created using TINTOlib. For instructions on how to generate images from tabular data, refer to the TINTOlib documentation on GitHub.\n",
    "\n",
    "Remember that you can set the training to be done with GPUs to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RKBgDwzjpCl"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QgI5BtKiDB2"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "See the paper from [Information Fusion Journal](https://doi.org/10.1016/j.inffus.2022.10.011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3h21kL1iDB2"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "See the paper from [SoftwareX](https://doi.org/10.1016/j.softx.2023.101391)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3bgmoMziDB2"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib in [GitHub](https://github.com/oeg-upm/TINTOlib-Documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VF2qPR36iDB2"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpU7pi6yjpCn"
   },
   "source": [
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 1. Description</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NL9RoFkEjpCq"
   },
   "source": [
    "The growing interest in the use of algorithms-based machine learning for predictive tasks has generated a large and diverse development of algorithms. However, it is widely known that not all of these algorithms are adapted to efficient solutions in certain tidy data format datasets. For this reason, novel techniques are currently being developed to convert tidy data into images with the aim of using vision models such as CNN or Vision Transformers (ViTs). TINTOlib offers the opportunity to convert tidy data into images through several techniques: TINTO, IGTD, REFINED, SuperTML, BarGraph, DistanceMatrix, Combination, FeatureWrap and BIE.\n",
    "\n",
    "In this tutorial, we develop a Hybrid Neural Network with synthetic images, which combines a CNN and a MLP.\n",
    "\n",
    "<figure><center>\n",
    "  <img src=\"../../Images/HyNN.png\" width=\"650\" height=\"400\" alt=\"Gráfica\">\n",
    "  <figcaption><blockquote>Hybrid Neural Network (MLP+CNN) architecture.</a></blockquote></figcaption>\n",
    "</center></figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFrF4C89jpCt"
   },
   "source": [
    "---\n",
    "<a id=\"section11\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.1. Main Features</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gruE0_sjpCu"
   },
   "source": [
    "- Supports all CSV data in **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "- For now, the algorithm converts tabular data for binary and multi-class classification problems into machine learning.\n",
    "- Input data formats:\n",
    "    - **Tabular files**: The input data could be in **[CSV](https://en.wikipedia.org/wiki/Comma-separated_values)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Dataframe***: The input data could be in **[Pandas Dataframe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html)**, taking into account the **[Tidy Data](https://www.jstatsoft.org/article/view/v059i10)** format.\n",
    "    - **Tidy Data**: The **target** (variable to be predicted) should be set as the last column of the dataset. Therefore, the first columns will be the features.\n",
    "    - All data must be in numerical form. TINTOlib does not accept data in string or any other non-numeric format.\n",
    "- Runs on **Linux**, **Windows** and **macOS** systems.\n",
    "- Compatible with **[Python](https://www.python.org/)** 3.7 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wisc9wFpiDB3"
   },
   "source": [
    "---\n",
    "<a id=\"section12\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.2. Citation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y9vKkMpYiDB3"
   },
   "source": [
    "**TINTOlib** is an python library that makes **Synthetic Images** from [Tidy Data](https://www.jstatsoft.org/article/view/v059i10) (also knows as **Tabular Data**).\n",
    "\n",
    "**Citing TINTO**: If you used TINTO in your work, please cite the **[SoftwareX](https://doi.org/10.1016/j.softx.2023.101391)**:\n",
    "\n",
    "```bib\n",
    "@article{softwarex_TINTO,\n",
    "    title = {TINTO: Converting Tidy Data into Image for Classification\n",
    "            with 2-Dimensional Convolutional Neural Networks},\n",
    "    journal = {SoftwareX},\n",
    "    author = {Manuel Castillo-Cara and Reewos Talla-Chumpitaz and\n",
    "              Raúl García-Castro and Luis Orozco-Barbosa},\n",
    "    year = {2023},\n",
    "    pages = {101391},\n",
    "    issn = {2352-7110},\n",
    "    doi = {https://doi.org/10.1016/j.softx.2023.101391}\n",
    "}\n",
    "```\n",
    "\n",
    "And use-case developed in **[INFFUS Paper](https://doi.org/10.1016/j.inffus.2022.10.011)**\n",
    "\n",
    "```bib\n",
    "@article{inffus_TINTO,\n",
    "    title = {A novel deep learning approach using blurring image\n",
    "            techniques for Bluetooth-based indoor localisation},\n",
    "    journal = {Information Fusion},\n",
    "    author = {Reewos Talla-Chumpitaz and Manuel Castillo-Cara and\n",
    "              Luis Orozco-Barbosa and Raúl García-Castro},\n",
    "    volume = {91},\n",
    "    pages = {173-186},\n",
    "    year = {2023},\n",
    "    issn = {1566-2535},\n",
    "    doi = {https://doi.org/10.1016/j.inffus.2022.10.011}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OqvRTgY_iDB3"
   },
   "source": [
    "---\n",
    "<a id=\"section13\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 1.3. Documentation and License</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aNUHCwbkiDB3"
   },
   "source": [
    "TINTOlib has a wide range of documentation on both GitHub and PiPY.\n",
    "\n",
    "Moreover, TINTOlib is free and open software with Apache 2.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3tgsO0BjpCj"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib in [GitHub](https://github.com/oeg-upm/TINTOlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jylws6vViDB3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in the official [Webpage](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uadaMY7piDB3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3EzYcjJjpC6"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwYF5A2njpC8"
   },
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 2. Libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En0WEV2AiDB3"
   },
   "source": [
    "---\n",
    "<a id=\"section21\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.1. System setup</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRG6JqzkiDB3"
   },
   "source": [
    "Before installing the libraries you must have the `mpi4py` package installed on the native (Linux) system. This link shows how to install it:\n",
    "- Link: [`mpi4py` in Linux](https://www.geeksforgeeks.org/how-to-install-python3-mpi4py-package-on-linux/)\n",
    "\n",
    "For example, in Linux:\n",
    "\n",
    "```\n",
    "    sudo apt-get install python3\n",
    "    sudo apt install python3-pip\n",
    "    sudo apt install python3-mpi4py\n",
    "```\n",
    "\n",
    "If you are in Windows, Mac or, also, Linux, you can install from PyPI if you want:\n",
    "```\n",
    "    sudo pip3 install mpi4py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAY_ANo7iDB3"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel or the system** so that it can load the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsI_HDzxiDB3"
   },
   "source": [
    "Now, once you have installed `mpi4py` you can install the PyPI libraries and dependences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8164,
     "status": "ok",
     "timestamp": 1729272078570,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "RqkZOO9EiDB4",
    "outputId": "2488c06b-9880-42cd-a2d7-170450f986a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tintolib\n",
      "  Downloading tintolib-0.0.26-py3-none-any.whl.metadata (22 kB)\n",
      "Downloading tintolib-0.0.26-py3-none-any.whl (53 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tintolib\n",
      "Successfully installed tintolib-0.0.26\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tintolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217448,
     "status": "ok",
     "timestamp": 1729272296015,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "8QcsTaIkiDB4",
    "outputId": "419248d0-3000-416c-f050-03240a5ebdbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pytorch_lightning\n",
      "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: TINTOlib in /usr/local/lib/python3.10/dist-packages (0.0.26)\n",
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl.metadata (355 bytes)\n",
      "Collecting keras_preprocessing\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting mpi4py\n",
      "  Downloading mpi4py-4.0.1.tar.gz (466 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (2024.9.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
      "Collecting bitstring\n",
      "  Downloading bitstring-4.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
      "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
      "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.4.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.12.2)\n",
      "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (from imblearn) (0.12.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras_preprocessing) (1.16.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
      "Collecting bitarray<3.0.0,>=2.9.0 (from bitstring)\n",
      "  Downloading bitarray-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.2.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.10.10)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.16.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.15.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (3.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (3.10)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (0.2.0)\n",
      "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitstring-4.2.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/71.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
      "Building wheels for collected packages: mpi4py\n",
      "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for mpi4py: filename=mpi4py-4.0.1-cp310-cp310-linux_x86_64.whl size=4266354 sha256=6dfc2f723bba3cfdf7b21ff97a4b99722d3d5a2727e9ae4fc3859de58f04dad9\n",
      "  Stored in directory: /root/.cache/pip/wheels/3c/ca/13/13218a83854023ccec184e3af482f0f038b434aa32c19afee8\n",
      "Successfully built mpi4py\n",
      "Installing collected packages: bitarray, mpi4py, lightning-utilities, keras_preprocessing, bitstring, torchmetrics, imblearn, pytorch_lightning\n",
      "Successfully installed bitarray-2.9.3 bitstring-4.2.3 imblearn-0.0 keras_preprocessing-1.1.2 lightning-utilities-0.11.8 mpi4py-4.0.1 pytorch_lightning-2.4.0 torchmetrics-1.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U torchmetrics pytorch_lightning TINTOlib imblearn keras_preprocessing mpi4py tifffile tqdm seaborn bitstring opencv-python pydot graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUAd86FYiDB5"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "Note that you must **restart the kernel** so that it can load the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SSsr9C3iDB5"
   },
   "source": [
    "---\n",
    "<a id=\"section22\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 2.2. Invoke the libraries</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AdHKnWYsEq_"
   },
   "source": [
    "The first thing we need to do is to declare the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 8344,
     "status": "ok",
     "timestamp": 1729272304351,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "PeeBbGxlpjFp",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#import cv2\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "#import openslide\n",
    "#from openslide.deepzoom import DeepZoomGenerator\n",
    "import tifffile as tifi\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score,mean_absolute_percentage_error\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import vgg16, vgg19, resnet50, mobilenet, inception_resnet_v2, densenet, inception_v3, xception, nasnet, ResNet152V2\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, InputLayer, LayerNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Adamax\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanAbsolutePercentageError\n",
    "from tensorflow.keras.layers import Input, Activation,MaxPooling2D, concatenate, AveragePooling2D, Concatenate\n",
    "from keras.utils import plot_model\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "#Models of TINTOlib\n",
    "from TINTOlib.barGraph import BarGraph\n",
    "from TINTOlib.combination import Combination\n",
    "from TINTOlib.distanceMatrix import DistanceMatrix\n",
    "from TINTOlib.igtd import IGTD\n",
    "from TINTOlib.refined import REFINED\n",
    "from TINTOlib.supertml import SuperTML\n",
    "from TINTOlib.tinto import TINTO\n",
    "from TINTOlib.featureWrap import FeatureWrap\n",
    "from TINTOlib.bie import BIE\n",
    "\n",
    "# SET RANDOM SEED FOR REPRODUCIBILITY\n",
    "SEED = 64\n",
    "#torch.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed(SEED)\n",
    "#torch.cuda.manual_seed_all(SEED)\n",
    "#torch.backends.cudnn.deterministic = True\n",
    "#torch.backends.cudnn.benchmark = False\n",
    "os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwS-cKUxjpDQ"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDL4LARWjpDT"
   },
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 3. Data processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXcRw78ljpDU"
   },
   "source": [
    "TINTOlib creates a folder structure to store images corresponding to each target in a problem. For regression problems, since there are no distinct classes, all images are stored in a single subfolder named images/. Additionally, a CSV file is generated containing:\n",
    "\n",
    "- The file paths of all images.\n",
    "- The target value for each image, which corresponds to a sample from the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEpojXVxiDB6"
   },
   "source": [
    "<a id=\"section31\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.1. Read the dataset</font>\n",
    "\n",
    "In this part, we proceed to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1729272304352,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "5qoLI0w6iDB6",
    "outputId": "a52316a7-303b-43b2-c7b2-1ce0ade11c23"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.02381</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.97188</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127    1.02381       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137    0.97188      2401.0  2.109842     37.86   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name = 'california_housing'\n",
    "\n",
    "#Read CSV\n",
    "df = pd.read_csv(f\"{dataset_name}.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729272304352,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "CLP8PZO8iDB6",
    "outputId": "b036f844-615f-44fa-b3b9-2afa87b5c95e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3O22drsWiDB6"
   },
   "source": [
    "To determine the appropriate size for a square image that contains all the feature pixels, you need to calculate the square root of the total number of features. The resulting value can be used for the methods that requires inserting the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729272304352,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "Qld-PfnhiDB6",
    "outputId": "47c14677-ef2e-494d-f71c-609e1c622f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Get the shape of the dataframe\n",
    "num_columns = df.shape[1]\n",
    "\n",
    "# Calculate number of columns - 1\n",
    "columns_minus_one = num_columns - 1\n",
    "\n",
    "# Calculate the square root for image size\n",
    "import math\n",
    "image_size = math.ceil(math.sqrt(columns_minus_one))\n",
    "print(image_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_fROCY5C__S"
   },
   "source": [
    "---\n",
    "<a id=\"section32\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.2. Create images with TINTOlib</font>\n",
    "\n",
    "We prepare the declaration of the classes with the TINTOlib method we want to transform. Note that TINTOlib has several methods and we will have to choose one of them since each method generates different images.\n",
    "\n",
    "In addition, we establish the paths where the dataset is located and also the folder where the images will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729272304352,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "oXYAlWzQC__T"
   },
   "outputs": [],
   "source": [
    "#Select the model and the parameters\n",
    "#problem_type = \"supervised\"\n",
    "problem_type = \"regression\"\n",
    "\n",
    "# Transformation methods\n",
    "#image_model = TINTO(problem=problem_type, blur=True, option='maximum', pixels=20, random_seed=SEED)\n",
    "#name = f\"TINTO_blur_maximum\"\n",
    "# image_model = REFINED(problem=problem_type, random_seed=SEED, zoom=1, n_processors=8)\n",
    "# name = f\"REFINED\"\n",
    "image_model = IGTD(problem=problem_type, scale=[image_size,image_size], fea_dist_method='Euclidean', image_dist_method='Euclidean', error='abs', max_step=30000, val_step=300, random_seed=SEED, zoom=4)\n",
    "# name = f\"IGTD_fEuclidean_iEuclidean_abs\"\n",
    "# image_model = BarGraph(problem=problem_type, zoom=2)\n",
    "# name = f\"BarGraph_zoom2\"\n",
    "# image_model = DistanceMatrix(problem=problem_type, zoom=2)\n",
    "# name = f\"DistanceMatrix_zoom2\"\n",
    "# image_model = Combination(problem=problem_type, zoom=2)\n",
    "# name = f\"Combination_zoom2\"\n",
    "# image_model = SuperTML(problem=problem_type, pixels=pixel, font_size=30, feature_importance=True, random_seed=SEED)\n",
    "# name = f\"SuperTML-VF_FS30\"\n",
    "# image_model = FeatureWrap(problem = problem_type, bins=10)\n",
    "# name = f\"FeatureWrap_bins10\"\n",
    "# image_model = BIE(problem = problem_type)\n",
    "# name = f\"BIE\"\n",
    "\n",
    "#Define the dataset path and the folder where the images will be saved\n",
    "results_folder = \"Results1\"\n",
    "images_folder = \"Synthetic_images\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2o7tCQeLiDB7"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qnVB31QRiDB7"
   },
   "source": [
    "---\n",
    "<a id=\"section33\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.3. Generate images</font>\n",
    "\n",
    "Now we can generate the images with the `generateImages()` generic function. Likewise, we create a dataset that will have the path of each of the samples with the corresponding image created for it.\n",
    "\n",
    "Note that each image is created based on a row, therefore, each numerical sample of the dataset will correspond to a particular image. In other words, we will have the same number of images as samples/rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41600,
     "status": "ok",
     "timestamp": 1729272345947,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "pZUsQljtiDB7",
    "outputId": "8215a615-7cfa-4c82-e5ca-0a8d2d07365d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic_images/regression.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAwAAAAMCAYAAABWdVznAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAACdAAAAnQGPcuduAAAASUlEQVR4nGP8+fPnfwYk4Ovri8xlyM3NReEzMZAIaK+B8du3byh+ePHiBYqCS5cu0dlJpPvh////KH748eMHigIODg46O4lkDQA/KBY5IGkxOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 12x12 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Generate the images if the folder does not exist\n",
    "if not os.path.exists(images_folder):\n",
    "    #Generate thet images\n",
    "    image_model.generateImages(df, images_folder)\n",
    "else:\n",
    "    print(\"The images are already generated\")\n",
    "\n",
    "img_paths = os.path.join(images_folder,problem_type+\".csv\")\n",
    "\n",
    "print(img_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klS9PZsUjpDV"
   },
   "source": [
    "---\n",
    "<a id=\"section34\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.4. Read Images</font>\n",
    "\n",
    "Now, we read the created images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1729272345948,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "XDURDHkViDB7"
   },
   "outputs": [],
   "source": [
    "imgs = pd.read_csv(img_paths)\n",
    "\n",
    "#imgs[\"images\"]= images_folder + \"\\\\\" + imgs[\"images\"]\n",
    "imgs[\"images\"]= images_folder + \"/\" + imgs[\"images\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14yNsiARiDB7"
   },
   "source": [
    "---\n",
    "<a id=\"section35\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 3.5. Mix images and tidy data</font>\n",
    "\n",
    "Since we are going to use hybrid networks, i.e. create a model in which we join a CNN for the images and a MLP for the tabular data, we are going to join it in order to integrate all the data in our hybrid model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Z40NH8fiDB7"
   },
   "source": [
    "Combine the images and tidy data in the same dataframe, split attributes and objective value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729272345948,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "yKeQBj_MiDB7",
    "outputId": "169361f6-9ea9-4a06-eef0-fa71691eeffc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        4.526\n",
      "1        3.585\n",
      "2        3.521\n",
      "3        3.413\n",
      "4        3.422\n",
      "         ...  \n",
      "20635    0.781\n",
      "20636    0.771\n",
      "20637    0.923\n",
      "20638    0.847\n",
      "20639    0.894\n",
      "Name: values, Length: 20640, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "combined_dataset = pd.concat([imgs,df],axis=1)\n",
    "# Drop target column and values which is a copy of target column\n",
    "df_x = combined_dataset.drop(df.columns[-1],axis=1).drop(\"values\",axis=1)\n",
    "df_y = combined_dataset[\"values\"]\n",
    "\n",
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_haEKIo7jpD1"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uF1lJWbojpD3"
   },
   "source": [
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 4. Pre-modelling phase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "930Evqn7iDB8"
   },
   "source": [
    "Once the data is ready, we load it into memory with an iterator in order to pass it to the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVZdTeAFiDB8"
   },
   "source": [
    "---\n",
    "<a id=\"section41\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 4.1. Data curation</font>\n",
    "\n",
    "Note that each method generates images of **different pixel size**. For example:\n",
    "- `TINTO` method has a parameter that you can specify the size in pixels which by default is 20.\n",
    "- Other parameters such as `Combined` generates the size automatically and you must obtain them from the _shape_ of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9awKGBUiDB8"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "You can see all information about TINTOlib documentation in [PyPI](https://tintolib.readthedocs.io/en/latest/installation.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKLyRonliDB9"
   },
   "source": [
    "Split in train/test/validation.\n",
    "\n",
    "Note that the partitioning of the images is also performed, in addition to the tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcaLT2ojiDB9"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<i class=\"fa fa-info-circle\" aria-hidden=\"true\"></i>\n",
    "💡 **Important!!!**:  Keep in mind that, depending on the method used, you need to identify the number of pixels in the image. For example, in TINTO it is specified as a parameter, but in IGTD it is done afterwards, once the image is created (and even the pixels of width and height can be different)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3685,
     "status": "ok",
     "timestamp": 1729272349626,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "9SSP6MF0iDB9",
    "outputId": "3a37f29d-9f86-41a2-dd41-52ad32c5e9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape:  (12, 12, 1)\n",
      "Attributres:  8\n",
      "Image size (pixels): 12\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_x, df_y, test_size=0.20, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.50, random_state=SEED)\n",
    "\n",
    "#TIDY DATA SPLITTED\n",
    "X_train_num = X_train.drop(\"images\",axis=1)\n",
    "X_val_num = X_val.drop(\"images\",axis=1)\n",
    "X_test_num = X_test.drop(\"images\",axis=1)\n",
    "\n",
    "#IMAGES\n",
    "# For 3 channels (RGB)\n",
    "\"\"\"X_train_img = np.array([cv2.imread(img) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.imread(img) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.imread(img) for img in X_test[\"images\"]])\"\"\"\n",
    "\n",
    "# For 1 channels (GRAY SCALE)\n",
    "X_train_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_train[\"images\"]])\n",
    "X_val_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_val[\"images\"]])\n",
    "X_test_img = np.array([cv2.imread(img,cv2.IMREAD_GRAYSCALE) for img in X_test[\"images\"]])\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale numerical data\n",
    "X_train_num = scaler.fit_transform(X_train_num)\n",
    "X_val_num = scaler.transform(X_val_num)\n",
    "X_test_num = scaler.transform(X_test_num)\n",
    "\n",
    "attributes = X_train_num.shape[1]\n",
    "height, width = X_train_img[0].shape\n",
    "channels = 1\n",
    "imgs_shape = (height, width, channels)\n",
    "\n",
    "print(\"Images shape: \",imgs_shape)\n",
    "print(\"Attributres: \",attributes)\n",
    "pixel=X_train_img[0].shape[0]\n",
    "print(\"Image size (pixels):\", pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729272349626,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "-yXiH9raiDB9",
    "outputId": "7568adf2-ce0d-4b25-8514-45aed0024157"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot an example image (e.g., the first image in the array)\n",
    "example_image = X_train_img[2]\n",
    "\n",
    "# Convert the image from BGR (OpenCV default) to RGB for correct color display\n",
    "example_image_rgb = cv2.cvtColor(example_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Display the image using matplotlib\n",
    "plt.imshow(example_image_rgb)\n",
    "plt.title(\"Example Image from X_train\")\n",
    "plt.axis('off')  # Hide the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729272349626,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "EHbOLni1iDB9",
    "outputId": "7030b8f7-8a53-442a-edb2-cb50409f6c9f"
   },
   "outputs": [],
   "source": [
    "X_train_img = X_train_img/255\n",
    "X_val_img = X_val_img/255\n",
    "X_test_img = X_test_img/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaP_OB1yC__b"
   },
   "source": [
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 5. Modeling hybrid network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE8aSKFOiDB9"
   },
   "source": [
    "Now we can start the CNN+MLP training. Before that we prepare the algorithm for reading data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "blXIsAISiDB9"
   },
   "source": [
    "---\n",
    "<a id=\"section51\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.1. FFNN for tabular data</font>\n",
    "\n",
    "This is an example of a simple and more complex FFNN for tabular data. Note that we are not looking for the optimization of the CNN+MLP but to show an example of TINTOlib execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 473,
     "status": "ok",
     "timestamp": 1729272376821,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "8YlEhQqrC__c"
   },
   "outputs": [],
   "source": [
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1058,
     "status": "ok",
     "timestamp": 1729272378478,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "fYZ3SErriDB-"
   },
   "outputs": [],
   "source": [
    "# Single branch FFNN\n",
    "ff_inputs = Input(shape = (attributes,))\n",
    "\n",
    "mlp_1 = Dense(64, activation='relu')(ff_inputs)\n",
    "mlp_1 = Dense(32, activation='relu')(mlp_1)\n",
    "mlp_1 = Dense(16, activation='relu')(mlp_1)\n",
    "ff_model = Model(inputs = ff_inputs, outputs = mlp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729272351739,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "4if65T5viDB-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-29 12:55:29.522543: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-11-29 12:55:29.522570: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2024-11-29 12:55:29.522574: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 13.50 GB\n",
      "2024-11-29 12:55:29.522591: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-11-29 12:55:29.522786: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Two branch FFNN\n",
    "\n",
    "ff_inputs = Input(shape = (attributes,))\n",
    "\n",
    "# * START BRANCH 1\n",
    "mlp_1 = Dense(1024, activation='relu')(ff_inputs)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(512, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(256, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(128, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(64, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(32, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "mlp_1 = Dense(16, activation='relu')(mlp_1)\n",
    "mlp_1 = BatchNormalization()(mlp_1)\n",
    "mlp_1 = Dropout(dropout)(mlp_1)\n",
    "\n",
    "# * START BRANCH 2\n",
    "mlp_2 = Dense(1024, activation='relu')(ff_inputs)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(512, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(256, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(128, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(64, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(32, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "mlp_2 = Dense(16, activation='relu')(mlp_2)\n",
    "mlp_2 = BatchNormalization()(mlp_2)\n",
    "mlp_2 = Dropout(dropout)(mlp_2)\n",
    "\n",
    "merged_tabular = Concatenate(axis=1)([mlp_1, mlp_2])\n",
    "\n",
    "ff_model = Model(inputs = ff_inputs, outputs = merged_tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzBvmQ6diDB-"
   },
   "source": [
    "---\n",
    "<a id=\"section52\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.2. CNN for TINTOlib images</font>\n",
    "\n",
    "This is an example of a simple and more complex CNN for TINTOlib images. Note that we are not looking for the optimization of the CNN+MLP but to show an example of TINTOlib execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 620,
     "status": "ok",
     "timestamp": 1729272381589,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "9PjW67GGiDB-"
   },
   "outputs": [],
   "source": [
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729272382073,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "E5IMUGO5iDB-"
   },
   "outputs": [],
   "source": [
    "# Single branch CNN\n",
    "#Input\n",
    "input_shape = Input(shape=imgs_shape)\n",
    "\n",
    "# CNN branch 1\n",
    "tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(input_shape)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "\n",
    "tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "\n",
    "tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "\n",
    "#Flatten\n",
    "merged = Flatten()(tower_1)\n",
    "\n",
    "#Dense layers\n",
    "out = Dense(128, activation='sigmoid')(merged)\n",
    "out = Dense(64, activation='sigmoid')(out)\n",
    "out = Dense(32, activation='sigmoid')(out)\n",
    "\n",
    "cnn_model = Model(input_shape, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729272351739,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "7GXdjvjiiDB-"
   },
   "outputs": [],
   "source": [
    "#Input\n",
    "input_shape = Input(shape=imgs_shape)\n",
    "\n",
    "# CNN branch 1\n",
    "tower_1 = Conv2D(16, (3,3), activation='relu',padding=\"same\")(input_shape)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "tower_1 = Conv2D(32, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "tower_1 = Conv2D(64, (3,3), activation='relu',padding=\"same\")(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = MaxPooling2D(2,2)(tower_1)\n",
    "tower_1 = Dropout(dropout)(tower_1)\n",
    "\n",
    "#CNN branch 2\n",
    "tower_2 = Conv2D(16, (5,5), activation='relu',padding=\"same\")(input_shape)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "tower_2 = Conv2D(32, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "tower_2 = Conv2D(64, (5,5), activation='relu',padding=\"same\")(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = AveragePooling2D(2,2)(tower_2)\n",
    "tower_2 = Dropout(dropout)(tower_2)\n",
    "\n",
    "#Concatenate CNN branches\n",
    "merged = Concatenate(axis=1)([tower_1, tower_2])\n",
    "\n",
    "#Flatten\n",
    "merged = Flatten()(merged)\n",
    "\n",
    "#Dense layers\n",
    "out = Dense(512, activation='relu')(merged)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(256, activation='relu')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(128, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(64, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "out = Dense(32, activation='sigmoid')(out)\n",
    "out = Dropout(dropout)(out)\n",
    "\n",
    "cnn_model = Model(input_shape, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DSroZztiDB-"
   },
   "source": [
    "---\n",
    "<a id=\"section53\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.3. Concatenate branches</font>\n",
    "\n",
    "Finally, we need to fuse the CNN and MLP branches. In this case, we use a direct concatenation of the output from the CNN branch with the output from the MLP branch, feeding them into a final fully connected neural network (FFNN) that will produce the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729272387230,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "st0NtOjhiDB_"
   },
   "outputs": [],
   "source": [
    "combinedInput = concatenate([ff_model.output, cnn_model.output])\n",
    "x = Dense(48, activation=\"relu\")(combinedInput)\n",
    "x = Dense(24, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "model = Model(inputs=[ff_model.input, cnn_model.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729272351739,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "vSNmyFfuDAAR"
   },
   "outputs": [],
   "source": [
    "combinedInput = concatenate([ff_model.output, cnn_model.output])\n",
    "x = Dense(64, activation=\"relu\")(combinedInput)\n",
    "x = Dense(32, activation=\"relu\")(combinedInput)\n",
    "x = Dense(1, activation=\"linear\")(x)\n",
    "model = Model(inputs=[ff_model.input, cnn_model.input], outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1WcJGN_iDB_"
   },
   "source": [
    "---\n",
    "<a id=\"section54\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.4. Metrics</font>\n",
    "\n",
    "Define metrics and some hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1729272387715,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "qmVREpu0DAAS"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def r_square(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    r2 = 1 - SS_res / (SS_tot + K.epsilon())\n",
    "    return r2\n",
    "\n",
    "METRICS = [\n",
    "    tf.keras.metrics.MeanSquaredError(name = 'mse'),\n",
    "    tf.keras.metrics.MeanAbsoluteError(name = 'mae'),\n",
    "    tf.keras.metrics.RootMeanSquaredError(name = 'rmse'),\n",
    "    r_square,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EH7p_tILiDB_"
   },
   "source": [
    "Print the hybrid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 1399,
     "status": "ok",
     "timestamp": 1729272389106,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "L7BMiZYTiDB_",
    "outputId": "5eff98e0-a12b-4ad6-f681-6268b5dca329"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x34fd55c10>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.makedirs(results_folder, exist_ok=True)\n",
    "\n",
    "# Redirect the summary output to the specified file\n",
    "with open(results_folder+\"/model_summary.txt\", \"w\") as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "# Desactivar la visualización automática de matplotlib\n",
    "plt.ioff()\n",
    "# Now, you can also save the model plot\n",
    "plot_model(model, to_file=results_folder+'model_plot.png', show_shapes=True, expand_nested=True)\n",
    "# Reactivar la visualización automática de matplotlib (opcional)\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dvu2kd9NiDB_"
   },
   "source": [
    "---\n",
    "<a id=\"section55\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 5.5. Compile and fit</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729272390534,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "-mUXAIeZDAAT"
   },
   "outputs": [],
   "source": [
    "opt = Adam(learning_rate=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729272390534,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "VdTkj_zOiDB_"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"mse\",\n",
    "    optimizer=opt,\n",
    "    metrics = METRICS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1729272391746,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "p2pjJhKCiDCA"
   },
   "outputs": [],
   "source": [
    "# Configure EarlyStopping for binary classification\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor the validation accuracy\n",
    "    min_delta=0.001,         # Minimum change in the monitored quantity to qualify as an improvement\n",
    "    patience=20,             # Number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,               # Log when training stops\n",
    "    mode='min',              # Maximize the accuracy; min the loss\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37064,
     "status": "ok",
     "timestamp": 1729272430063,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "pKx7VY7-iDCA",
    "outputId": "cc18dae9-1e2c-4189-bc14-08459fc50f21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_113', 'keras_tensor_101']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n",
      "2024-11-29 13:15:45.841943: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m515/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 0.9613 - mae: 0.7330 - mse: 0.9613 - r_square: 0.2255 - rmse: 0.9715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manwest/Library/Python/3.9/lib/python/site-packages/keras/src/models/functional.py:225: UserWarning: The structure of `inputs` doesn't match the expected structure: ['keras_tensor_113', 'keras_tensor_101']. Received: the structure of inputs=('*', '*')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 0.9603 - mae: 0.7325 - mse: 0.9603 - r_square: 0.2264 - rmse: 0.9709 - val_loss: 0.5200 - val_mae: 0.5267 - val_mse: 0.5200 - val_r_square: 0.5731 - val_rmse: 0.7211\n",
      "Epoch 2/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4983 - mae: 0.5108 - mse: 0.4983 - r_square: 0.5952 - rmse: 0.7059 - val_loss: 0.4895 - val_mae: 0.5119 - val_mse: 0.4895 - val_r_square: 0.5974 - val_rmse: 0.6996\n",
      "Epoch 3/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4720 - mae: 0.4914 - mse: 0.4720 - r_square: 0.6166 - rmse: 0.6870 - val_loss: 0.4754 - val_mae: 0.5013 - val_mse: 0.4754 - val_r_square: 0.6081 - val_rmse: 0.6895\n",
      "Epoch 4/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4568 - mae: 0.4801 - mse: 0.4568 - r_square: 0.6289 - rmse: 0.6758 - val_loss: 0.4616 - val_mae: 0.4884 - val_mse: 0.4616 - val_r_square: 0.6196 - val_rmse: 0.6794\n",
      "Epoch 5/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4440 - mae: 0.4708 - mse: 0.4440 - r_square: 0.6393 - rmse: 0.6663 - val_loss: 0.4503 - val_mae: 0.4806 - val_mse: 0.4503 - val_r_square: 0.6285 - val_rmse: 0.6711\n",
      "Epoch 6/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 53ms/step - loss: 0.4347 - mae: 0.4632 - mse: 0.4347 - r_square: 0.6468 - rmse: 0.6593 - val_loss: 0.4412 - val_mae: 0.4716 - val_mse: 0.4412 - val_r_square: 0.6365 - val_rmse: 0.6643\n",
      "Epoch 7/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4267 - mae: 0.4576 - mse: 0.4267 - r_square: 0.6533 - rmse: 0.6532 - val_loss: 0.4359 - val_mae: 0.4670 - val_mse: 0.4359 - val_r_square: 0.6408 - val_rmse: 0.6603\n",
      "Epoch 8/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 51ms/step - loss: 0.4189 - mae: 0.4527 - mse: 0.4189 - r_square: 0.6597 - rmse: 0.6472 - val_loss: 0.4309 - val_mae: 0.4610 - val_mse: 0.4309 - val_r_square: 0.6461 - val_rmse: 0.6564\n",
      "Epoch 9/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 52ms/step - loss: 0.4114 - mae: 0.4479 - mse: 0.4114 - r_square: 0.6655 - rmse: 0.6414 - val_loss: 0.4249 - val_mae: 0.4533 - val_mse: 0.4249 - val_r_square: 0.6518 - val_rmse: 0.6518\n",
      "Epoch 10/10\n",
      "\u001b[1m516/516\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 55ms/step - loss: 0.4027 - mae: 0.4422 - mse: 0.4027 - r_square: 0.6723 - rmse: 0.6345 - val_loss: 0.4158 - val_mae: 0.4439 - val_mse: 0.4158 - val_r_square: 0.6597 - val_rmse: 0.6449\n",
      "Restoring model weights from the end of the best epoch: 10.\n"
     ]
    }
   ],
   "source": [
    "model_history= model.fit(\n",
    "    x=[X_train_num, X_train_img], y=y_train,\n",
    "    validation_data=([X_val_num, X_val_img], y_val),\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    callbacks = [early_stopper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729272430063,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "BcGghwkIDAAW",
    "outputId": "1440b4bc-a09b-4451-9bcf-bd0ccb9ea403"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mae', 'mse', 'r_square', 'rmse', 'val_loss', 'val_mae', 'val_mse', 'val_r_square', 'val_rmse'])\n"
     ]
    }
   ],
   "source": [
    "print(model_history.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMRV4Ee1DAAX"
   },
   "source": [
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\" size=6> 6. Results</font>\n",
    "\n",
    "Finally, we can evaluate our hybrid model with the images created by TINTOlib in any of the ways represented below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_D_Dc1kiDCA"
   },
   "source": [
    "---\n",
    "<a id=\"section61\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.1. Train/Validation representation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729272430063,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "H5UXDjQwDAAY",
    "outputId": "4b57aef9-3e7e-4bed-9338-09c20919c211"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsQ0lEQVR4nO3dfXRU9Z3H8c88ZfI4eQBCgiQ8aAQEsSDIKtW1hVVj4WBrte2ixdp1j2wooOsD2R7t9liMelxLq10qHo91j7DUraV1XdCitmBtsaiLq0J5fghiCErI5IFMkpm7f0wmJJCnmdyZO5n7fp1zz725c2fuN442n37v796fwzAMQwAAACZwWl0AAABIHQQLAABgGoIFAAAwDcECAACYhmABAABMQ7AAAACmIVgAAADTECwAAIBp3Ik+YSgU0rFjx5STkyOHw5Ho0wMAgBgYhqGGhgaNGjVKTmfvfYmEB4tjx46ppKQk0acFAAAmqK6u1ujRo3t9PeHBIicnR1K4MJ/Pl+jTAwCAGPj9fpWUlHT+He9NwoNF5PKHz+cjWAAAMMT0N4yBwZsAAMA0BAsAAGAaggUAADBNwsdYAAAQYRiG2tvbFQwGrS7F9lwul9xu96AfBUGwAABYorW1VZ9++qmam5utLgUdMjMzVVxcrLS0tJg/g2ABAEi4UCikgwcPyuVyadSoUUpLS+OhiRYyDEOtra06ceKEDh48qLKysj4fgtUXggUAIOFaW1sVCoVUUlKizMxMq8uBpIyMDHk8Hh0+fFitra1KT0+P6XMYvAkAsEys/68Y8WHG98E3CgAATEOwAAAApiFYAAAQhauvvlrLly+3uoykRbAAAACmSY1gEQpJK1dKt94qNTRYXQ0AALaVGsHC6ZR++lPphRekPXusrgYAEC3DkJqarFkMI+ay6+rq9O1vf1v5+fnKzMxUeXm59u7d2/n64cOHNX/+fOXn5ysrK0uTJ0/Wxo0bO9+7cOFCjRgxQhkZGSorK9Nzzz036H+UVkud51hMmCDV1kq7d0uXXmp1NQCAaDQ3S9nZ1py7sVHKyorprbfddpv27t2rl19+WT6fT/fff7+uv/567dy5Ux6PRxUVFWptbdXWrVuVlZWlnTt3Krvj93zggQe0c+dObdq0ScOHD9e+fft0+vRpM38zS6RWsHjrrXCwAAAgziKB4u2339YVV1whSVq7dq1KSkr0m9/8RjfddJOOHDmiG2+8URdffLEkafz48Z3vP3LkiKZNm6YZM2ZIksaOHZvw3yEeUidYTJwYXv/1r9bWAQCIXmZmuHNg1bljsGvXLrndbs2aNatz37BhwzRhwgTt2rVLkrR06VItXrxYv/vd7zR37lzdeOONmjp1qiRp8eLFuvHGG/X+++/rmmuu0Q033NAZUIay1BhjIYU7FhIdCwAYihyO8OUIK5Y4zlHyD//wDzpw4IBuvfVWffjhh5oxY4aefPJJSVJ5ebkOHz6su+66S8eOHdOcOXN0zz33xK2WRIk6WHzyySe65ZZbNGzYMGVkZOjiiy/Wu+++G4/aohPpWOzZE75LBACAOJo0aZLa29v1zjvvdO77/PPPtXv3bl100UWd+0pKSnTnnXfq17/+tf75n/9ZzzzzTOdrI0aM0KJFi/TCCy9o1apVWrNmTUJ/h3iI6lJIXV2dZs+erS996UvatGmTRowYob179yo/Pz9e9Q3c2LGSxyOdPi1VV0tjxlhdEQAghZWVlWnBggW644479PTTTysnJ0crVqzQeeedpwULFkiSli9frvLycl144YWqq6vT73//e02aNEmS9OCDD+rSSy/V5MmTFQgE9Morr3S+NpRFFSweffRRlZSUdLsdZty4caYXFRO3Wyork3buDI+zIFgAAOLsueee07JlyzRv3jy1trbqqquu0saNG+XxeCRJwWBQFRUVOnr0qHw+n6677jr9+Mc/liSlpaWpsrJShw4dUkZGhq688kqtX7/eyl/HFA7DGPgNvBdddJGuvfZaHT16VFu2bNF5552nf/qnf9Idd9zR63sCgYACgUDnz36/XyUlJaqvr5fP5xtc9Wf72tekDRukn/xEWrrU3M8GAJimpaVFBw8e1Lhx42Kenhvm6+t78fv9ys3N7ffvd1RjLA4cOKDVq1errKxMr732mhYvXqylS5fq+eef7/U9VVVVys3N7VxKSkqiOWV0uDMEAABLRRUsQqGQpk+frocffljTpk3TP/7jP+qOO+7Qz3/+817fU1lZqfr6+s6lurp60EX3ijtDAACwVFTBori4uNtIVyk8KvbIkSO9vsfr9crn83Vb4oaOBQAAlooqWMyePVu7z+oG7NmzR2OSZaBkpGNx7BiTkQEAYIGogsVdd92lbdu26eGHH9a+ffu0bt06rVmzRhUVFfGqLzp5edLIkeFtLocAAJBwUQWLmTNnasOGDfrP//xPTZkyRQ899JBWrVqlhQsXxqu+6DHOAgAAy0Q9V8i8efM0b968eNRijokTpa1bGWcBAIAFUmeukAg6FgAAWIZgAQBAAo0dO1arVq3q9fXbbrtNN9xwQ8LqMVvqBQsmIwMAwDKpFyzGjpXS0qSWFqmP52sAAADzpV6wcLnCk5FJDOAEAJhmzZo1GjVqlEJndcMXLFig22+/XZK0f/9+LViwQCNHjlR2drZmzpyp119/fVDnDQQCWrp0qQoLC5Wenq4vfvGL2r59e+frdXV1WrhwoUaMGKGMjAyVlZV1Thba2tqqJUuWqLi4WOnp6RozZoyqqqoGVU9/or4rZEiYMEH6+OPwOIvrrrO6GgBAPwzDUHNbsyXnzvRkyuFw9HvcTTfdpO9973v6/e9/rzlz5kiSTp48qVdffVUbN26UJDU2Nur666/XypUr5fV69R//8R+aP3++du/erdLS0pjqu++++/TSSy/p+eef15gxY/TYY4/p2muv1b59+1RQUKAHHnhAO3fu1KZNmzR8+HDt27dPp0+fliT99Kc/1csvv6wXX3xRpaWlqq6uju/UGkrVYMGjvQFgSGlua1Z2VbYl526sbFRWWla/x+Xn56u8vFzr1q3rDBa/+tWvNHz4cH3pS1+SJF1yySW65JJLOt/z0EMPacOGDXr55Ze1ZMmSqGtramrS6tWr9Ytf/ELl5eWSpGeeeUabN2/Ws88+q3vvvVdHjhzRtGnTNGPGDEnhwaERR44cUVlZmb74xS/K4XAk5EnZqXcpROLOEABAXCxcuFAvvfSSAoGAJGnt2rX65je/Kacz/Oe0sbFR99xzjyZNmqS8vDxlZ2dr165dfc6p1Zf9+/erra1Ns2fP7tzn8Xh02WWXadeuXZKkxYsXa/369frCF76g++67T3/60586j73tttu0Y8cOTZgwQUuXLtXvfve7WH/1AaNjAQCwXKYnU42VjZade6Dmz58vwzD0P//zP5o5c6beeust/fjHP+58/Z577tHmzZv1+OOP64ILLlBGRoa+/vWvq7W1NR6lS5LKy8t1+PBhbdy4UZs3b9acOXNUUVGhxx9/XNOnT9fBgwe1adMmvf7667r55ps1d+5c/epXv4pbPakZLCIdi08/lfx+KZ4zqgIABs3hcAzocoTV0tPT9bWvfU1r167Vvn37NGHCBE2fPr3z9bffflu33XabvvrVr0oKdzAOHToU8/nOP/98paWl6e233+68jNHW1qbt27dr+fLlnceNGDFCixYt0qJFi3TllVfq3nvv1eOPPy5J8vl8+sY3vqFvfOMb+vrXv67rrrtOJ0+eVEFBQcx19SU1g0VurlRUJNXUhC+HzJxpdUUAgBSxcOFCzZs3Tx9//LFuueWWbq+VlZXp17/+tebPny+Hw6EHHnjgnLtIopGVlaXFixfr3nvvVUFBgUpLS/XYY4+publZ3/3udyVJDz74oC699FJNnjxZgUBAr7zyiiZNmiRJeuKJJ1RcXKxp06bJ6XTqv/7rv1RUVKS8vLyYa+pPagYLKdy1IFgAAEz25S9/WQUFBdq9e7f+/u//vttrTzzxhG6//XZdccUVGj58uO6//375/f5Bne+RRx5RKBTSrbfeqoaGBs2YMUOvvfaa8vPzJUlpaWmqrKzUoUOHlJGRoSuvvFLr16+XJOXk5Oixxx7T3r175XK5NHPmTG3cuLFzTEg8OAzDMOL26T3w+/3Kzc1VfX29fPG8RHHnndLTT0vf/770ox/F7zwAgKi1tLTo4MGDGjdunNLT060uBx36+l4G+vc7Ne8KkbgzBAAAC6RusODOEAAAEi51g0WkY7F3rxQMWlsLAAA2kbrBYswYyeuVAgEmIwMAIEFSN1gwGRkAAAmXusFCYgAnACS5BN+YiH6Y8X2kdrBgACcAJCWPxyNJam62ZkZT9CzyfUS+n1ik7gOyJDoWAJCkXC6X8vLyVFtbK0nKzBzY1OWID8Mw1NzcrNraWuXl5cnlcsX8WakdLOhYAEDSKioqkqTOcAHr5eXldX4vsUrtYBHpWNTUSPX14TlEAABJweFwqLi4WIWFhWpra7O6HNvzeDyD6lREpHaw8Pmk4uLwLKe7d0uXXWZ1RQCAs7hcLlP+oCE5pPbgTYlxFgAAJFDqBwvGWQAAkDCpHyzoWAAAkDCpHyzoWAAAkDCpHyyYjAwAgIRJ/WBRWiqlp0utrdKhQ1ZXAwBASkv9YNF1MjLGWQAAEFepHywkBnACAJAg9ggWDOAEACAh7BEs6FgAAJAQ9ggWdCwAAEgIewSLCy8Mr48fl06dsrQUAABSmT2Chc8njRoV3uZyCAAAcWOPYCExzgIAgASwT7BgnAUAAHFnn2BBxwIAgLizT7CgYwEAQNzZJ1hEOhb79knt7dbWAgBAirJPsGAyMgAA4s4+wcLpPPM8C8ZZAAAQF/YJFhLjLAAAiDN7BQvuDAEAIK4IFgAAwDRRBYt//dd/lcPh6LZMjFxeGAq4FAIAQFy5o33D5MmT9frrr5/5AHfUH2GdyODN2lqprk7Kz7e2HgAAUkzUqcDtdquoqCgetcRfTo503nnSJ5+EL4f8zd9YXREAACkl6jEWe/fu1ahRozR+/HgtXLhQR44ciUdd8cM4CwAA4iaqYDFr1iz94he/0KuvvqrVq1fr4MGDuvLKK9XQ0NDrewKBgPx+f7fFUoyzAAAgbqK6FFJeXt65PXXqVM2aNUtjxozRiy++qO9+97s9vqeqqko//OEPB1elmehYAAAQN4O63TQvL08XXnih9u3b1+sxlZWVqq+v71yqq6sHc8rBo2MBAEDcDCpYNDY2av/+/SouLu71GK/XK5/P122xFJORAQAQN1EFi3vuuUdbtmzRoUOH9Kc//Ulf/epX5XK59K1vfSte9ZmvpETKyJDa2qSDB62uBgCAlBJVsDh69Ki+9a1vacKECbr55ps1bNgwbdu2TSNGjIhXfeZjMjIAAOImqsGb69evj1cdiTVxovTBB+FxFvPmWV0NAAApw15zhURwZwgAAHFhz2DBnSEAAMSFPYMFHQsAAOLCnsEiMnjzxAnp5ElrawEAIIXYM1hkZ0ujR4e36VoAAGAaewYLicshAADEgX2DBQM4AQAwnX2DBR0LAABMZ99gQccCAADT2TdYRDoW+/eH5w0BAACDZt9gMXq0lJnJZGQAAJjIvsGCycgAADCdfYOFxDgLAABMZu9gwZ0hAACYyt7Bgo4FAACmsnewoGMBAICp7B0sIoM3P/tM+vxza2sBACAF2DtYZGVJJSXhbboWAAAMmr2DhcTlEAAATESwYAAnAACmIVjQsQAAwDQECzoWAACYhmDBZGQAAJiGYHHeeeG7Q9rbpQMHrK4GAIAhjWDBZGQAAJiGYCExzgIAAJMQLCTuDAEAwCQEC4mOBQAAJiFYSHQsAAAwCcFCOjN48/PPwxOSAQCAmBAsJCkzUyotDW/TtQAAIGYEi4jIOAuCBQAAMSNYRETGWTCAEwCAmBEsIuhYAAAwaASLCDoWAAAMGsEiIhIsDhxgMjIAAGJEsIjoOhnZ/v1WVwMAwJBEsIhwOHhQFgAAg0Sw6IpHewMAMCgEi67oWAAAMCgEi67oWAAAMCgEi6663nJqGNbWAgDAEESw6KqsLDyIs66OycgAAIgBwaIrJiMDAGBQCBZnY5wFAAAxI1icjTtDAACIGcHibExGBgBAzAgWZ2MyMgAAYjaoYPHII4/I4XBo+fLlJpWTBCIdiwMHpNZWa2sBAGCIiTlYbN++XU8//bSmTp1qZj3WKy6WsrOlYJDJyAAAiFJMwaKxsVELFy7UM888o/z8fLNrshaTkQEAELOYgkVFRYW+8pWvaO7cuf0eGwgE5Pf7uy1Jj1tOAQCIiTvaN6xfv17vv/++tm/fPqDjq6qq9MMf/jDqwixFxwIAgJhE1bGorq7WsmXLtHbtWqWnpw/oPZWVlaqvr+9cqqurYyo0oehYAAAQk6g6Fu+9955qa2s1ffr0zn3BYFBbt27VU089pUAgIJfL1e09Xq9XXq/XnGoTpWvHwjDC4y4AAEC/ogoWc+bM0Ycfftht33e+8x1NnDhR999//zmhYsjqOhnZiRNSYaHVFQEAMCREFSxycnI0ZcqUbvuysrI0bNiwc/YPaRkZ0pgx0qFD4a4FwQIAgAHhyZu9YZwFAABRi/qukLP94Q9/MKGMJDRhgvTqq9wZAgBAFOhY9IaOBQAAUSNY9IZnWQAAEDWCRW8iHYuDB6VAwNpaAAAYIggWvSkqknJymIwMAIAoECx643Cc6VpwOQQAgAEhWPQlMs6CAZwAAAwIwaIvDOAEACAqBIu+cMspAABRIVj05ezJyAAAQJ8IFn2JTEZ26pRUW2t1NQAAJD2CRV/S06WxY8PbjLMAAKBfBIv+MM4CAIABI1j0hztDAAAYMIJFf+hYAAAwYASL/tCxAABgwAgW/WEyMgAABoxg0Z+RIyWfTwqFpH37rK4GAICkRrDoD5ORAQAwYASLgWAyMgAABoRgMRB0LAAAGBCCxUDQsQAAYEAIFgPBZGQAAAwIwWIgLrhAcjql+nrp+HGrqwEAIGkRLAaCycgAABgQgsVA8WhvAAD6RbAYKB7tDQBAvwgWA0XHAgCAfhEsBoqOBQAA/SJYDFTXychaWqytBQCAJEWwGKjCQik3N/wcCyYjAwCgRwSLgeo6GRnjLAAA6BHBIhqMswAAoE8Ei2gwGRkAAH0iWESDycgAAOgTwSIaXTsWTEYGAMA5CBbROP/88GRkfr9UU2N1NQAAJB2CRTS8XmncuPA24ywAADgHwSJa3HIKAECvCBbR4pZTAAB6RbCIFh0LAAB6RbCIFh0LAAB6RbCIVqRjceiQdPq0paUAAJBsCBbRGjFCystjMjIAAHpAsIgWk5EBANArgkUsGGcBAECPCBaxoGMBAECPCBaxoGMBAECPogoWq1ev1tSpU+Xz+eTz+XT55Zdr06ZN8aoteTEZGQAAPYoqWIwePVqPPPKI3nvvPb377rv68pe/rAULFujjjz+OV33J6fzzJZdLamiQPv3U6moAAEgaUQWL+fPn6/rrr1dZWZkuvPBCrVy5UtnZ2dq2bVu86ktOaWnS+PHhbS6HAADQKeYxFsFgUOvXr1dTU5Muv/zyXo8LBALy+/3dlpQQGWfBAE4AADpFHSw+/PBDZWdny+v16s4779SGDRt00UUX9Xp8VVWVcnNzO5eSkpJBFZw0GMAJAMA5og4WEyZM0I4dO/TOO+9o8eLFWrRokXbu3Nnr8ZWVlaqvr+9cqqurB1Vw0uCWUwAAzuGO9g1paWm64IILJEmXXnqptm/frp/85Cd6+umnezze6/XK6/UOrspkRMcCAIBzDPo5FqFQSIFAwIxahpZIx+LwYSYjAwCgQ1Qdi8rKSpWXl6u0tFQNDQ1at26d/vCHP+i1116LV33Ja/hwKT9fqquT9u6Vpk61uiIAACwXVbCora3Vt7/9bX366afKzc3V1KlT9dprr+nv/u7v4lVf8opMRvbnP4fHWRAsAACILlg8++yz8apjaJowIRwsGGcBAIAk5goZHO4MAQCgG4LFYHBnCAAA3RAsBoPJyAAA6IZgMRjjx4cnI2tslI4ds7oaAAAsR7AYjLS08EynEpdDAAAQwWLwmIwMAIBOBIvB6jrOAgAAmyNYDBYdCwAAOhEsBotbTgEA6ESwGKyuk5E1N1tbCwAAFiNYDNbw4VJBQXh7715rawEAwGIECzPwaG8AACQRLMzBOAsAACQRLMxBxwIAAEkEC3PQsQAAQBLBwhxMRgYAgCSChTnGj5fcbqmpSfrkE6urAQDAMgQLM3g8TEYGAIAIFubh0d4AABAsTMNkZAAAECxMQ8cCAACChWnoWAAAQLAwTaRjceRI+O4QAABsiGBhlmHDwovEZGQAANsiWJiJR3sDAGyOYGEmHu0NALA5goWZ6FgAAGyOYGEmOhYAAJsjWJip6y2noZC1tQAAYAGChZnGjQtPRtbczGRkAABbIliYyeORLrggvM04CwCADREszMY4CwCAjREszMajvQEANkawMBuTkQEAbIxgYTY6FgAAGyNYmC3SsaiuZjIyAIDtECzMVlAgjRgR3t6zx9paAABIMIJFPDDOAgBgUwSLeOCWUwCATREs4oHJyAAANkWwiAc6FgAAmyJYxAOTkQEAbIpgEQ/jxoXnDTl9Wjp61OpqAABIGIJFPLjdTEYGALAlgkW8MM4CAGBDBIt44c4QAIANESzihY4FAMCGogoWVVVVmjlzpnJyclRYWKgbbrhBu/nD2TMmIwMA2FBUwWLLli2qqKjQtm3btHnzZrW1temaa65RE5NtnSvSsTh6VGpstLYWAAASxGEYhhHrm0+cOKHCwkJt2bJFV1111YDe4/f7lZubq/r6evl8vlhPPTSMHCnV1krvvSdNn251NQAAxGygf78HNcaivr5eklRQUNDrMYFAQH6/v9tiG0xGBgCwmZiDRSgU0vLlyzV79mxNmTKl1+OqqqqUm5vbuZSUlMR6yqGHcRYAAJuJOVhUVFToo48+0vr16/s8rrKyUvX19Z1LdXV1rKcceuhYAABsxh3Lm5YsWaJXXnlFW7du1ejRo/s81uv1yuv1xlTckMctpwAAm4mqY2EYhpYsWaINGzbozTff1Lhx4+JVV2qIXArZs4fJyAAAthBVx6KiokLr1q3Tb3/7W+Xk5KimpkaSlJubq4yMjLgUOKSNHXtmMrLqamnMGKsrAgAgrqLqWKxevVr19fW6+uqrVVxc3Ln88pe/jFd9Q5vbLZWVhbcZZwEAsIGoOhaDeOSFfU2YIO3cGR5nce21VlcDAEBcMVdIvDEZGQDARggW8cadIQAAGyFYxBsdCwCAjRAs4i3SsTh2TGposLYWAADijGARb3l54cnIpPDzLAAASGEEi0Tg0d4AAJsgWCQCk5EBAGyCYJEIdCwAADZBsEgEOhYAAJsgWCRCpGPBZGQAgBRHsEiEsWOltDSppUU6csTqagAAiBuCRSK4XExGBgCwBYJFovBobwCADRAsEoVHewMAbIBgkSh0LAAANkCwSBQ6FgAAGyBYJEqkY/Hpp5Lfb20tAADECcEiUXJzpaKi8DaXQwAAKYpgkUiMswAApDiCRSLxaG8AQIojWCQSk5EBAFIcwSKR6FgAAFIcwSKRuk5GFgxaWwsAAHFAsEikMWMkr1cKBJiMDACQkggWicRkZACAFEewSDRuOQUApDCCRaLxaG8AQAojWCQaHQsAQAojWCQaHQsAQAojWCRapGNRUyPV11tbCwAAJiNYJJrPJxUXh7e5HAIASDEECyswzgIAkKIIFlZgnAUAIEURLKxAxwIAkKIIFlZgMjIAQIoiWFgh0rHYu5fJyAAAKYVgYYXSUik9PTwZ2eHDVlcDAIBpCBZWYDIyAECKIlhYhXEWAIAURLCwSmScBR0LAEAKIVhYhVtOAQApiGBhFR6SBQBIQQQLq1x4YXh9/Lh06pSlpQAAYBaChVV8PmnUqPA2l0MAACmCYGElxlkAAFIMwcJKjLMAAKQYgoWV6FgAAFIMwcJKPCQLAJBiog4WW7du1fz58zVq1Cg5HA795je/iUNZNsFkZACAFBN1sGhqatIll1yin/3sZ/Gox14ik5G1tkqHDlldDQAAg+aO9g3l5eUqLy+PRy3243SGn2fxf/8XHsB5/vlWVwQAwKDEfYxFIBCQ3+/vtqALxlkAAFJI3INFVVWVcnNzO5eSkpJ4n3JoYTIyAEAKiXuwqKysVH19fedSXV0d71MOLXQsAAApJOoxFtHyer3yer3xPs3QRccCAJBCeI6F1SKTkdXWSnV11tYCAMAgRR0sGhsbtWPHDu3YsUOSdPDgQe3YsUNHjhwxuzZ7yMmRzjsvvM3lEADAEBd1sHj33Xc1bdo0TZs2TZJ09913a9q0aXrwwQdNL842eLQ3ACBFRD3G4uqrr5ZhGPGoxb4mTpTefJNxFgCAIY8xFsmAjgUAIEUQLJIB06cDAFIEwSIZRDoW+/ZJ7e3W1gIAwCAQLJJBSYmUkSG1tTEZGQBgSCNYJIPIZGQSl0MAAEMawSJZ8GhvAEAKIFgkCx7tDQBIAQSLZEHHAgCQAggWyYKOBQAgBRAskkVk8OaJE9LJk9bWAgBAjAgWySI7Wxo9OrzN5RAAwBBFsEgmPNobADDEESySCY/2BgAMcQSLZELHAgAwxBEskgkdCwDAEOe2ugCz3Lf5PrW0tyg/PV956XnKS89TfkZ4O7IvPyNf2WnZcjqSNE9FOhb794fnDfF4rK0HAIAopUyweP6D51XbVNvvcU6HU7ne3HNCx9kB5JzXOvalu9Pj90uMHi1lZkrNzdKKFVJpqVRQIOXnn7ukx7EOAABilDLBovKLlTrRdEKnWk6prqWu2/pUyynVna5TIBhQyAiprqVOdS11MZ0n3Z3ecxDxngkfvYUUn9cnl9PV+4c7ndLFF0vvvCM98UTfhWRk9Bw4egoiZ+9LS+v1Y4OhoNpCbWoLtnVbtwZbz9nXFuzY38vxDjlUmFWoouwiFWUXaUTWCLmdKfOvHACgBw7DMIxEntDv9ys3N1f19fXy+XyJPLVa2ltUd7rn0NFXIIlsGxr8Pyqf13dO6OgWRE61KHP7B2pvblBbc6NaW5rU1tKktsBptQWa1dbaolaX1OaU2s5at7rO3dfm0rnHux1qczvV6nZ07DPCiwyFHPH718Ehh4ZnDu8MGmcvI7NGdm4XZBTI4XDErRYAQHQG+vfbVsFiMEJGSA2Bhr4Dyek6nQr0/FpzW7PVv0LMPMGOJdSxGE6lySWPwy2Ps2NxpcnjSlOaxyuPxyuPJ0Mht0u1wXrVBD5XbcvnChmhgZ/T6dHI7JE9ho6zl+y07Dj+9gAAaeB/v+lLD5DT4VRueq5y03Njen9rsLXvQBJ5raVOzW3N8rg88jg9Z9ZOj9Jcaefud3XsP2tfj8fLKU9Lm9KaWuRpbJanoVmehiZ5/E3y+BuVdqpRnlN+eer88tTVy3OyXu6TdXLUnZLq67v8NqGOpW3Av3/QIX2WKR3PcahmeLpqCtJUk+dWjc+pmixDNZkh1XjbdNwT0ElX+PLKUf9RHfUf7fezszxZ3UJIUVYP3ZDskRqZNVJetzfarw4AEAU6FhiYYFA6dUqqqzt3OXmy5/11dVJTU3g5fXrApwq4pNosqSa7+3L8rJ8/zZaaex8u0qP8kFdFjhwVuXwq8uSrKG2YijILNTKzUEW+USrKPU9FBaUaXjBaLl+ulJUlucnfAEDHAuZyuaRhw8JLLILB8N0ujY3hoNHH2tvUpJLGRpWc/fqpJulo9+MbWxvDoaOHIHJ2IGlzSXXOgOoU0K7QZ1JA4aXh3HKdIamwSSpqlEacdsjlcMrhcMrhdEoda4ezyz6nUw6nq/Nnh9N1Zr8rst8lh8t15lhX5LjI/vA68nPnsS53x8/u8Gtu95nPdbrkkKNzPEpku+ta0jn7BvJa13Vvn23V5wVDQYWMkIJGUMFQ0Jy10fGZZn1el3Vvtbocrh67kANZd+tIxvD+aLqfva3dTjdjoXAOggUSw+WScnLCi4myDUMXnD6tC84OKGeFEqOxUXWNJ1Rz+oRqWj5TTVudatpP6bjRoBpHk2pcp1XjCajG264TGSGFnFJNTniRDEnBjsUEkStJ7eZ8HGAlt9OtNFeavC5veO329vlzj8cM5r19/EzwsQbBAkObwxF+9kdmZt+HSSroWC7q5yPbQ+060Vir46eOqubzwzpx6hMFWwMy2tul9jYZ7e0y2tpktLfJCLZLbe0ygm0yuqwVbA+/3t4uI9je8d5g53si+9XeLiMY7LIvGH5vsF1Ge3i/Iq8Hg+Gl438nDUmG48x6oPu6rtXHa9EcM5Bzdfs8l1OG0ynD6ei+7TyzrW77uqwdDrkcLjkdTrmcLrkcTrkcrvDi7LI43B3bHWuXu2PbLaerY7/LE94fWbs9HdseudxuuVxp4X1uj1zu8LbT5ZHL07Hf4z2zjpwnUkcva2ekXqer19u7zVh33gpu4uf2NAC7PdSu9lB70g5QjyaUeFweuRwuubt8l+dsd3x30Wz3+Xlx2s7yZFkWqggWwFncTreKfaNU7BsllV5mdTndGYbU3i4FAlJr67nrnvZ1Xbe1hZfW1p7X/e0LDPC4rutQT3cDRdo2KcTpDD8t1+2Obn32dn/LOcdm9X2sd4Cf29Nnu7o/dydkhHp9xk0gGFBrsFWtwVYF2sPbkX0D/bnbvhjfe3b4CQQDCgQDifw3ISkcu/uYinOKLTk3wQIYShyOM/+jP1SEQrGFmP72tbebt472PT2NeQ+FwuEtkEJ/xLr+++bxyOnxyNuxnBNC3O4zi8vV/eeBvuZO7+f1jvd7e3896JQCTkOtTqPLOqRWR0gBR0itjqACCoZ/VlCtjqBaFVTAaFebggrKUFCG2o2ggg5DQSOo9i5jY9pD7R372jvHypyzfdax8d5uD7WfE6j6fBhjnBEsAMSX0yl5veElVUTC0mBDTdelp329LfE4tr2HQT+GcaYTNkS4JGV2LKZxOMKBxumM09ojudJ7fn2An2E4HQq5nGp3OhR0OZTRbt1/bwQLAIhWKoalyGW2WEJL5H1nL8FgbK8l8vW2ATyPJ/LPJok5FA5VnX2Kygel3NieuzRYBAsAQPfLHhkZVleTWJEOVCgUDhypsM7KsuwfJ8ECAGBvkQ4UTOG0ugAAAJA6CBYAAMA0BAsAAGAaggUAADANwQIAAJiGYAEAAExDsAAAAKYhWAAAANMQLAAAgGkIFgAAwDQECwAAYBqCBQAAMA3BAgAAmCbhs5sahiFJ8vv9iT41AACIUeTvduTveG8SHiwaGhokSSUlJYk+NQAAGKSGhgbl5ub2+rrD6C96mCwUCunYsWPKycmRw+Ew7XP9fr9KSkpUXV0tn89n2uciNnwfyYfvJLnwfSQXvo/+GYahhoYGjRo1Sk5n7yMpEt6xcDqdGj16dNw+3+fz8S9FEuH7SD58J8mF7yO58H30ra9ORQSDNwEAgGkIFgAAwDQpEyy8Xq9+8IMfyOv1Wl0KxPeRjPhOkgvfR3Lh+zBPwgdvAgCA1JUyHQsAAGA9ggUAADANwQIAAJiGYAEAAEyTMsHiZz/7mcaOHav09HTNmjVLf/nLX6wuyZaqqqo0c+ZM5eTkqLCwUDfccIN2795tdVno8Mgjj8jhcGj58uVWl2Jbn3zyiW655RYNGzZMGRkZuvjii/Xuu+9aXZZtBYNBPfDAAxo3bpwyMjJ0/vnn66GHHup3Pgz0LiWCxS9/+Uvdfffd+sEPfqD3339fl1xyia699lrV1tZaXZrtbNmyRRUVFdq2bZs2b96strY2XXPNNWpqarK6NNvbvn27nn76aU2dOtXqUmyrrq5Os2fPlsfj0aZNm7Rz507927/9m/Lz860uzbYeffRRrV69Wk899ZR27dqlRx99VI899piefPJJq0sbslLidtNZs2Zp5syZeuqppySF5yMpKSnR9773Pa1YscLi6uztxIkTKiws1JYtW3TVVVdZXY5tNTY2avr06fr3f/93/ehHP9IXvvAFrVq1yuqybGfFihV6++239dZbb1ldCjrMmzdPI0eO1LPPPtu578Ybb1RGRoZeeOEFCysbuoZ8x6K1tVXvvfee5s6d27nP6XRq7ty5+vOf/2xhZZCk+vp6SVJBQYHFldhbRUWFvvKVr3T77wSJ9/LLL2vGjBm66aabVFhYqGnTpumZZ56xuixbu+KKK/TGG29oz549kqQPPvhAf/zjH1VeXm5xZUNXwichM9tnn32mYDCokSNHdts/cuRI/fWvf7WoKkjhztHy5cs1e/ZsTZkyxepybGv9+vV6//33tX37dqtLsb0DBw5o9erVuvvuu/Uv//Iv2r59u5YuXaq0tDQtWrTI6vJsacWKFfL7/Zo4caJcLpeCwaBWrlyphQsXWl3akDXkgwWSV0VFhT766CP98Y9/tLoU26qurtayZcu0efNmpaenW12O7YVCIc2YMUMPP/ywJGnatGn66KOP9POf/5xgYZEXX3xRa9eu1bp16zR58mTt2LFDy5cv16hRo/hOYjTkg8Xw4cPlcrl0/PjxbvuPHz+uoqIii6rCkiVL9Morr2jr1q0aPXq01eXY1nvvvafa2lpNnz69c18wGNTWrVv11FNPKRAIyOVyWVihvRQXF+uiiy7qtm/SpEl66aWXLKoI9957r1asWKFvfvObkqSLL75Yhw8fVlVVFcEiRkN+jEVaWpouvfRSvfHGG537QqGQ3njjDV1++eUWVmZPhmFoyZIl2rBhg958802NGzfO6pJsbc6cOfrwww+1Y8eOzmXGjBlauHChduzYQahIsNmzZ59z+/WePXs0ZswYiypCc3OznM7ufwpdLpdCoZBFFQ19Q75jIUl33323Fi1apBkzZuiyyy7TqlWr1NTUpO985ztWl2Y7FRUVWrdunX77298qJydHNTU1kqTc3FxlZGRYXJ395OTknDO+JSsrS8OGDWPciwXuuusuXXHFFXr44Yd188036y9/+YvWrFmjNWvWWF2abc2fP18rV65UaWmpJk+erP/93//VE088odtvv93q0oYuI0U8+eSTRmlpqZGWlmZcdtllxrZt26wuyZYk9bg899xzVpeGDn/7t39rLFu2zOoybOu///u/jSlTphher9eYOHGisWbNGqtLsjW/328sW7bMKC0tNdLT043x48cb3//+941AIGB1aUNWSjzHAgAAJIchP8YCAAAkD4IFAAAwDcECAACYhmABAABMQ7AAAACmIVgAAADTECwAAIBpCBYAAMA0BAsAAGAaggUAADANwQIAAJiGYAEAAEzz/4FXENmchC6BAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['loss'], color = 'red', label = 'loss')\n",
    "plt.plot(model_history.history['val_loss'], color = 'green', label = 'val loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1823,
     "status": "ok",
     "timestamp": 1729272431882,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "X1ophmZYDAAZ",
    "outputId": "a7d15e3d-5434-4e20-b042-aadc3bd68e52"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model_history.history['rmse'], color = 'red', label = 'rmse')\n",
    "plt.plot(model_history.history['val_rmse'], color = 'green', label = 'val rmse')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTTR7sIMiDCA"
   },
   "source": [
    "---\n",
    "<a id=\"section62\"></a>\n",
    "# <font color=\"#004D7F\" size=5> 6.2. Validation/Test evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729272431883,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "IS4eN6UjiDCA",
    "outputId": "f81ec313-336b-44c5-ffec-a92b92347389",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4423 - mae: 0.4286 - mse: 0.4423 - r_square: 0.6282 - rmse: 0.6640\n"
     ]
    }
   ],
   "source": [
    "score_test= model.evaluate([X_val_num, X_val_img], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1458,
     "status": "ok",
     "timestamp": 1729272433336,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "ItKAjj6wDAAb",
    "outputId": "e70e4e6b-dac9-4dd1-df2a-53f663afecb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m65/65\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Mean Absolute Percentage Error: 0.20935642134689966\n",
      "Mean Absolute Error: 0.4229141135548159\n",
      "Mean Squared Error: 0.4065094115692171\n",
      "Root Mean Squared Error: 0.6375809059007469\n",
      "R2 Score: 0.7098306174074271\n",
      "Metrics saved to Results/Regression/california_housing_TINTO_blur_maximum/metrics.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([X_test_num,X_test_img])\n",
    "\n",
    "test_mape = mean_absolute_percentage_error(y_test, prediction)\n",
    "test_mae = mean_absolute_error(y_test, prediction)\n",
    "test_mse = mean_squared_error(y_test, prediction)\n",
    "test_rmse = mean_squared_error(y_test, prediction, squared=False)\n",
    "test_r2 = r2_score(y_test, prediction)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Absolute Percentage Error:\", test_mape)\n",
    "print(\"Mean Absolute Error:\", test_mae)\n",
    "print(\"Mean Squared Error:\", test_mse)\n",
    "print(\"Root Mean Squared Error:\", test_rmse)\n",
    "print(\"R2 Score:\", test_r2)\n",
    "\n",
    "# Define the metrics and their values\n",
    "metrics = {\n",
    "    \"Mean Absolute Percentage Error\": test_mape,\n",
    "    \"Mean Absolute Error\": test_mae,\n",
    "    \"Mean Squared Error\": test_mse,\n",
    "    \"Root Mean Squared Error\": test_rmse,\n",
    "    \"R2 Score\": test_r2,\n",
    "}\n",
    "\n",
    "# Save the metrics to a text file\n",
    "with open(f\"{results_folder}/metrics.txt\", \"w\") as file:\n",
    "    for metric, value in metrics.items():\n",
    "        file.write(f\"{metric}: {value}\\n\")\n",
    "\n",
    "print(f\"Metrics saved to {results_folder}/metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729272433337,
     "user": {
      "displayName": "Jiayun Liu",
      "userId": "16866032985979885782"
     },
     "user_tz": -120
    },
    "id": "xGMBiuNAiDCB",
    "outputId": "0c270146-175b-4605-a7d3-953b9a5a2852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Mean Squared Error: 0.38563331961631775\n",
      "Train R2 Score: 0.6910852789878845\n",
      "Val Mean Squared Error: 0.4282904863357544\n",
      "Val R2 Score: 0.6525911688804626\n"
     ]
    }
   ],
   "source": [
    "train_mse = model_history.history[\"mse\"][-1]\n",
    "train_r2 = model_history.history[\"r_square\"][-1]\n",
    "\n",
    "val_mse = model_history.history[\"val_mse\"][-1]\n",
    "val_r2 = model_history.history[\"val_r_square\"][-1]\n",
    "\n",
    "print(\"Train Mean Squared Error:\", train_mse)\n",
    "print(\"Train R2 Score:\", train_r2)\n",
    "\n",
    "print(\"Val Mean Squared Error:\", val_mse)\n",
    "print(\"Val R2 Score:\", val_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ciBS76mpjGU"
   },
   "source": [
    "<div style=\"text-align: right\"> <font size=5> <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a></font></div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"text-align: right\"> <font size=6><i class=\"fa fa-coffee\" aria-hidden=\"true\" style=\"color:#004D7F\"></i> </font></div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
